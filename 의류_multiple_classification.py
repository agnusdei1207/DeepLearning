# -*- coding: utf-8 -*-
"""의류 multiple-Classification.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ci1qTqEtLk9DX0FzvQRy9jcyADMH2MFq
"""

import tensorflow as tf
import numpy as np
from tensorflow.keras.datasets import fashion_mnist

data = fashion_mnist.load_data()

# 이중구조
print(len(data[0]))
print(len(data[1]))

# 이중튜플로 나누기
(X_train, y_train),(X_test,y_test) = data

# 6만장, 28*28 px
print(X_train.shape)
print(y_train.shape)
print(X_test.shape)
print(y_test.shape)

# 데이터 시각화
import matplotlib.pyplot as plt
plt.imshow(X_train[0]) # cmap: gray 흑백
print(f"정답 : {y_train[15000]}") # 정답 분류
print(f"정답 유니크 : {np.unique(y_train)}") 
print(f"유니크 카운트 : {np.bincount(y_train)}")

#plt.hist(X_train[0])
plt.show()

# 모델 설계 준비
from tensorflow.python.keras.engine.input_layer import InputLayer
from tensorflow.keras import Sequential # 핵심
from tensorflow.keras.layers import Dense, InputLayer, Flatten
from tensorflow.keras.utils import to_categorical # 다중분류

## 다중분류 시 정답데이터를 반드시 확률정보로 바꾸어야 학습을 시킬 수 있다. *****
print(f"정답 :{y_train[:10]}")
print(f"{to_categorical(y_train[:10])}") # 원핫인코딩과 비슷한 구조 / 10 종류 = 10 개의 선 = 10 개의 확률

# 다중분류로 정답데이터 분류
y_train_one_hot = to_categorical(y_train)
y_test_one_hot = to_categorical(y_test)

# 모델 구조 설계
mnist_model = Sequential()
mnist_model.add(InputLayer(input_shape=(28,28))) # (sample, 가로px, 세로px, 색상수3)
# CNN 2차원 데이터를 처리하는 알고리즘이 중간에 들어온다
mnist_model.add(Flatten()) # 데이터를 1차원으로 평평하게 만들어주는 레이어
mnist_model.add(Dense(32, activation="sigmoid"))
mnist_model.add(Dense(64, activation="sigmoid"))
mnist_model.add(Dense(128, activation="sigmoid"))
mnist_model.add(Dense(256, activation="sigmoid"))
mnist_model.add(Dense(64, activation="sigmoid"))
mnist_model.add(Dense(32, activation="sigmoid"))
# 출력층 / 다중분류 시 유니크 값에 해당하는 총 10개의 확률값이 필요하다.
mnist_model.add(Dense(10, activation="softmax")) # softmax : 현재/전체 데이터 비율 >> 사람이 보기 쉽게 합산을 1.0 으로 만들어 줌

# 학습/평가 방법 설정
mnist_model.compile(loss="sparse_categorical_crossentropy", # sparse_categorical_crossentropy : 내부에서 확률을 계산하여 높은 확률인 녀석으로 분류해주는 기능
                    optimizer="Adam", # default : GD / Adam : 최신 버전
                    metrics=["accuracy"]) # metrics : 정확도를 보여 줌

# 학습
mnist_history = mnist_model.fit(X_train, y_train_one_hot,
                validation_split=0.3, # 학습과 검증 분리 7:3
                epochs=100)

# 시각화
plt.figure(figsize=(15,5))
plt.plot(mnist_history.history["loss"],label="loss")
plt.plot(mnist_history.history["val_loss"],label="val_loss") # 과대적합 여부를 확인하기 위해 검증 데이터도 그래프 시각화
plt.legend()
plt.show()

# 모델 평가
mnist_model.evaluate(X_test, y_test_one_hot)

!df -h # 할당량 확인 /dev/sda1  Size 총량 Avail 할당량

# 모델 저장
mnist_model.save("my_fasion_mode.h5")