# -*- coding: utf-8 -*-
"""Compare Activation SGD,Adam/relu,sigmoid,.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1-SL13_QqnmkCj_Eu4NKmi9VtEt7AW7eB
"""

# 활성화 함수 : sigmoid / 경사하강법 : SGD
# 활성화 함수 : relu / 경사하강법 : SGD
# 활성화 함수 : relu / 경사하강법 : Adam

from tensorflow.keras.datasets import fashion_mnist
import matplotlib.pyplot as plt
from tensorflow.keras.utils import to_categorical

(X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()

y_train_categorial = to_categorical(y_train) # 정답 데이터 분류형 확률 정보로 변경
y_test_categorical = to_categorical(y_test)

from tensorflow.keras import Sequential
from tensorflow.keras.layers import InputLayer, Dense, Flatten # Flatten : 데이터를 평평하게 만들어 주는 함수
from tensorflow.keras.optimizers import SGD, Adam # 활성화 및 경사하강법 커스텀을 위해 클래스  임포트

# 1. sigmoid + SGD

model1 = Sequential()
model1.add(InputLayer(input_shape=(28,28))) # 입력층
model1.add(Flatten())# 평평하게 만들어주는 Flatten 층
model1.add(Dense(128, activation="sigmoid")) # 항아리 모양
model1.add(Dense(256, activation="sigmoid"))
model1.add(Dense(128, activation="sigmoid"))
model1.add(Dense(64, activation="sigmoid"))
model1.add(Dense(10, activation="softmax"))# 출력층

model1.compile(loss="categorical_crossentropy", # 원핫 인코딩을 내부에서 하고 싶다면 sparse_categorical_crossentropy 사용하기
            optimizer=SGD(lr= 0.01),
            metrics=["accuracy"]) # SGD 객체 생성

h1 = model1.fit(X_train, y_train_categorial,
                validation_split=0.3, epochs=100)

# 2. relu + SGD

model2 = Sequential()
model2.add(InputLayer(input_shape=(28,28))) # 입력층
model2.add(Flatten())# 평평하게 만들어주는 Flatten 층
model2.add(Dense(128, activation="sigmoid")) # 항아리 모양
model2.add(Dense(256, activation="relu"))
model2.add(Dense(128, activation="relu"))
model2.add(Dense(64, activation="relu")) # 층이 얕기 때문에 전부 relu 로 바꾸게 되면 학습이 전혀 안 될 수 있음
model2.add(Dense(10, activation="softmax"))# 출력층

model2.compile(loss="categorical_crossentropy", # 원핫 인코딩을 내부에서 하고 싶다면 sparse_categorical_crossentropy 사용하기
            optimizer=SGD(lr= 0.01),
            metrics=["accuracy"]) # SGD 객체 생성

h2 = model2.fit(X_train, y_train_categorial,
                validation_split=0.3, epochs=100)

# 3. relu + Adam

model3 = Sequential()
model3.add(InputLayer(input_shape=(28,28))) # 입력층
model3.add(Flatten())# 평평하게 만들어주는 Flatten 층
model3.add(Dense(128, activation="sigmoid")) # 항아리 모양
model3.add(Dense(256, activation="relu"))
model3.add(Dense(128, activation="relu"))
model3.add(Dense(64, activation="relu")) # 층이 얕기 때문에 전부 relu 로 바꾸게 되면 학습이 전혀 안 될 수 있음
model3.add(Dense(10, activation="softmax"))# 출력층

model3.compile(loss="categorical_crossentropy", # 원핫 인코딩을 내부에서 하고 싶다면 sparse_categorical_crossentropy 사용하기
            optimizer=Adam(lr = 0.01),
            metrics=["accuracy"]) # SGD 객체 생성

h3 = model3.fit(X_train, y_train_categorial,
                validation_split=0.3, epochs = 100)

plt.figure(figsize=(15,5)) # 그림 그릴 판 설정
# 1. sigmoid+SGD
plt.plot(h1.history["accuracy"], label = "sigmoid+SGD")
plt.plot(h1.history["val_accuracy"], label = "val_sigmoid+SGD")

# 2. relu+SGD
plt.plot(h2.history["accuracy"], label = "relu+SGD")
plt.plot(h2.history["val_accuracy"], label = "val_relu+SGD")
# 3. relu+Adam
plt.plot(h3.history["accuracy"], label = "relu+Adam")
plt.plot(h3.history["val_accuracy"], label = "val_relu+Adam")

plt.legend() # 범례
plt.show()
